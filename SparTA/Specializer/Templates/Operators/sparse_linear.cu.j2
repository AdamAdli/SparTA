{# Copyright (c) Microsoft Corporation. #}
{# Licensed under the MIT license. #}

#include <torch/extension.h>
#include <ATen/ATen.h>
#include <cuda.h>

#include "sparse_matmul.cuh"

const int M = {{ GLOBAL_M_VALUE }};
const int K = {{ GLOBAL_K_VALUE }};
const int N = {{ GLOBAL_N_VALUE }};
const int BM = {{ BLOCK_SIZE_M_VALUE }};
const int BK = {{ BLOCK_SIZE_K_VALUE }};
const int BN = {{ BLOCK_SIZE_N_VALUE }};
const int TM = {{ THREAD_SIZE_M_VALUE }};
const int TK = {{ THREAD_SIZE_K_VALUE }};
const int TN = {{ THREAD_SIZE_N_VALUE }};

{% if BIASED %}
at::Tensor sparse_linear_forward(
    torch::Tensor A,
    torch::Tensor W_val,
    torch::Tensor W_row,
    torch::Tensor W_col,
    torch::Tensor bias
)
{
    cudaSetDevice(A.get_device());
    torch::Tensor C = torch::empty({M, N}, A.options());

    const dim3 dimBlock(BN / TN, BM / TM);
    const dim3 dimGrid(N / BN, M / BM);
    
    BLOCK_SPARSE_MATMUL_BIASED<{{ TYPE }}, M, K, N, BM, BK, BN, TM, TK, TN><<<dimGrid, dimBlock>>>(
        A.data_ptr<{{ TYPE }}>(),
        W_val.data_ptr<{{ TYPE }}>(),
        W_row.data_ptr<int>(),
        W_col.data_ptr<int>(),
        bias.data_ptr<{{ TYPE }}>(),
        C.data_ptr<{{ TYPE }}>()
    );

    // AT_DISPATCH_FLOATING_TYPES(A.{{ TYPE }}(), "sparse_linear", ([&]{
    //     BLOCK_SPARSE_MATMUL_BIASED<{{ TYPE }}, M, K, N, BM, BK, BN, TM, TK, TN><<<dimGrid, dimBlock>>>(
    //         A.data_ptr<{{ TYPE }}>(),
    //         W_val.data_ptr<{{ TYPE }}>(),
    //         W_row.data_ptr<int>(),
    //         W_col.data_ptr<int>(),
    //         bias.data_ptr<{{ TYPE }}>(),
    //         C.data_ptr<{{ TYPE }}>()
    //     );
    // }));
    return C;
}
{% else %}
{% endif %}

PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {
  m.def("forward", &sparse_linear_forward, "Sparse linear forward");
}